{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "06f10b11-8e8d-4a78-af31-42d3d40bacc8",
   "metadata": {
    "id": "06f10b11-8e8d-4a78-af31-42d3d40bacc8"
   },
   "source": [
    "# Assignment 15 Solution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73a21c29-a4db-4658-8de9-2c72461044d3",
   "metadata": {
    "id": "73a21c29-a4db-4658-8de9-2c72461044d3"
   },
   "source": [
    "**1. Deep Learning.**\n",
    "\n",
    "**a. Build a DNN with five hidden layers of 100 neurons each, He initialization, and the ELU activation function.**\n",
    "\n",
    "**b. Using Adam optimization and early stopping, try training it on MNIST but only on digits 0 to 4, as we will use transfer learning for digits 5 to 9 in the next exercise. You will need a softmax output layer with five neurons, and as always make sure to save checkpoints at regular intervals and save the final model so you can reuse it later.**\n",
    "\n",
    "**c. Tune the hyperparameters using cross-validation and see what precision you can achieve.**\n",
    "\n",
    "**d. Now try adding Batch Normalization and compare the learning curves: is it converging faster than before? Does it produce a better model?**\n",
    "\n",
    "**e. Is the model overfitting the training set? Try adding dropout to every layer and try\n",
    "again. Does it help?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1a9a270-ea46-4c60-8d8d-38aa0da2b373",
   "metadata": {
    "id": "a1a9a270-ea46-4c60-8d8d-38aa0da2b373"
   },
   "source": [
    "**Ans:** **a. Build a DNN with five hidden layers of 100 neurons each, He initialization, and the ELU activation function.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "28caf7ae-bc6d-4a5d-a791-d4bf2ff38077",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\anacondaInstalledHere\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_2\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_2\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ dense_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)                 │          <span style=\"color: #00af00; text-decoration-color: #00af00\">78,500</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)                 │          <span style=\"color: #00af00; text-decoration-color: #00af00\">10,100</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)                 │          <span style=\"color: #00af00; text-decoration-color: #00af00\">10,100</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)                 │          <span style=\"color: #00af00; text-decoration-color: #00af00\">10,100</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)                 │          <span style=\"color: #00af00; text-decoration-color: #00af00\">10,100</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,010</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ dense_9 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)                 │          \u001b[38;5;34m78,500\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_10 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)                 │          \u001b[38;5;34m10,100\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_11 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)                 │          \u001b[38;5;34m10,100\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_12 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)                 │          \u001b[38;5;34m10,100\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_13 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)                 │          \u001b[38;5;34m10,100\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_14 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)                  │           \u001b[38;5;34m1,010\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">119,910</span> (468.40 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m119,910\u001b[0m (468.40 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">119,910</span> (468.40 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m119,910\u001b[0m (468.40 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.initializers import HeNormal\n",
    "\n",
    "# Define the model\n",
    "model = Sequential()\n",
    "\n",
    "# Add the first hidden layer with He initialization and ELU activation\n",
    "model.add(Dense(100, activation='elu', kernel_initializer=HeNormal(), input_shape=(784,)))\n",
    "\n",
    "# Add four more hidden layers with He initialization and ELU activation\n",
    "for _ in range(4):\n",
    "    model.add(Dense(100, activation='elu', kernel_initializer=HeNormal()))\n",
    "\n",
    "# Add the output layer\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Display the model summary\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "QRneWrfvBC70",
   "metadata": {
    "id": "QRneWrfvBC70"
   },
   "source": [
    "**b. Using Adam optimization and early stopping, try training it on MNIST but only on digits 0 to 4, as we will use transfer learning for digits 5 to 9 in the next exercise. You will need a softmax output layer with five neurons, and as always make sure to save checkpoints at regular intervals and save the final model so you can reuse it later.**\n",
    "\n",
    "**Ans:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "278b4d2f-b6cc-4d56-b081-55705c76760b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m954/957\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9437 - loss: 0.1759\n",
      "Epoch 1: val_loss improved from inf to 0.04262, saving model to training_checkpoints/cp-0001.weights.h5\n",
      "\u001b[1m957/957\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.9438 - loss: 0.1756 - val_accuracy: 0.9866 - val_loss: 0.0426\n",
      "Epoch 2/10\n",
      "\u001b[1m944/957\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9839 - loss: 0.0531\n",
      "Epoch 2: val_loss improved from 0.04262 to 0.02968, saving model to training_checkpoints/cp-0002.weights.h5\n",
      "\u001b[1m957/957\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9838 - loss: 0.0531 - val_accuracy: 0.9901 - val_loss: 0.0297\n",
      "Epoch 3/10\n",
      "\u001b[1m942/957\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9896 - loss: 0.0327\n",
      "Epoch 3: val_loss did not improve from 0.02968\n",
      "\u001b[1m957/957\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9895 - loss: 0.0327 - val_accuracy: 0.9891 - val_loss: 0.0346\n",
      "Epoch 4/10\n",
      "\u001b[1m952/957\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9892 - loss: 0.0307\n",
      "Epoch 4: val_loss did not improve from 0.02968\n",
      "\u001b[1m957/957\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9892 - loss: 0.0307 - val_accuracy: 0.9899 - val_loss: 0.0302\n",
      "Epoch 5/10\n",
      "\u001b[1m940/957\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9920 - loss: 0.0226\n",
      "Epoch 5: val_loss did not improve from 0.02968\n",
      "\u001b[1m957/957\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9920 - loss: 0.0227 - val_accuracy: 0.9909 - val_loss: 0.0338\n",
      "Epoch 6/10\n",
      "\u001b[1m957/957\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9943 - loss: 0.0190\n",
      "Epoch 6: val_loss did not improve from 0.02968\n",
      "\u001b[1m957/957\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9943 - loss: 0.0190 - val_accuracy: 0.9901 - val_loss: 0.0373\n",
      "Epoch 7/10\n",
      "\u001b[1m957/957\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9954 - loss: 0.0150\n",
      "Epoch 7: val_loss did not improve from 0.02968\n",
      "\u001b[1m957/957\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9953 - loss: 0.0150 - val_accuracy: 0.9848 - val_loss: 0.0464\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "import os\n",
    "\n",
    "# Load the MNIST dataset\n",
    "(x_train_full, y_train_full), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "# Filter digits 0 to 4\n",
    "train_mask = (y_train_full < 5)\n",
    "test_mask = (y_test < 5)\n",
    "x_train = x_train_full[train_mask]\n",
    "y_train = y_train_full[train_mask]\n",
    "x_test = x_test[test_mask]\n",
    "y_test = y_test[test_mask]\n",
    "\n",
    "# Preprocess the data\n",
    "x_train = x_train.reshape(-1, 28*28).astype('float32') / 255.0\n",
    "x_test = x_test.reshape(-1, 28*28).astype('float32') / 255.0\n",
    "\n",
    "# Define the model\n",
    "model = Sequential([\n",
    "    Dense(100, activation='elu', kernel_initializer='he_normal', input_shape=(784,)),\n",
    "    Dense(100, activation='elu', kernel_initializer='he_normal'),\n",
    "    Dense(100, activation='elu', kernel_initializer='he_normal'),\n",
    "    Dense(100, activation='elu', kernel_initializer='he_normal'),\n",
    "    Dense(100, activation='elu', kernel_initializer='he_normal'),\n",
    "    Dense(5, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Define callbacks\n",
    "checkpoint_path = \"training_checkpoints/cp-{epoch:04d}.weights.h5\"\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "cp_callback = ModelCheckpoint(filepath=checkpoint_path,\n",
    "                              save_weights_only=True,\n",
    "                              save_best_only=True,\n",
    "                              verbose=1)\n",
    "early_stopping_callback = EarlyStopping(monitor='val_loss', patience=5)\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(x_train, y_train,\n",
    "                    epochs=10,\n",
    "                    batch_size=32,\n",
    "                    validation_data=(x_test, y_test),\n",
    "                    callbacks=[cp_callback, early_stopping_callback])\n",
    "\n",
    "# Save the final model\n",
    "model.save(\"mnist_model_0_to_4.h5\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3sR7WOPGB4dX",
   "metadata": {
    "id": "3sR7WOPGB4dX"
   },
   "source": [
    "**c. Tune the hyperparameters using cross-validation and see what precision you can achieve.**\n",
    "\n",
    "**Ans:** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "70020f34-463d-46f3-adfe-7cc18dbdff44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with params: {'activation': 'relu', 'hidden_layers': 3, 'optimizer': 'adam', 'units': 50}\n",
      "Validation accuracy: 0.9796052972475687\n",
      "Training with params: {'activation': 'relu', 'hidden_layers': 3, 'optimizer': 'adam', 'units': 100}\n",
      "Validation accuracy: 0.9870245456695557\n",
      "Training with params: {'activation': 'relu', 'hidden_layers': 3, 'optimizer': 'adam', 'units': 200}\n",
      "Validation accuracy: 0.9868283271789551\n",
      "Training with params: {'activation': 'relu', 'hidden_layers': 3, 'optimizer': 'rmsprop', 'units': 50}\n",
      "Validation accuracy: 0.9864361683527628\n",
      "Training with params: {'activation': 'relu', 'hidden_layers': 3, 'optimizer': 'rmsprop', 'units': 100}\n",
      "Validation accuracy: 0.9854884147644043\n",
      "Training with params: {'activation': 'relu', 'hidden_layers': 3, 'optimizer': 'rmsprop', 'units': 200}\n",
      "Validation accuracy: 0.9860438307126363\n",
      "Training with params: {'activation': 'relu', 'hidden_layers': 4, 'optimizer': 'adam', 'units': 50}\n",
      "Validation accuracy: 0.9843444426854452\n",
      "Training with params: {'activation': 'relu', 'hidden_layers': 4, 'optimizer': 'adam', 'units': 100}\n",
      "Validation accuracy: 0.9855536023775736\n",
      "Training with params: {'activation': 'relu', 'hidden_layers': 4, 'optimizer': 'adam', 'units': 200}\n",
      "Validation accuracy: 0.9877435564994812\n",
      "Training with params: {'activation': 'relu', 'hidden_layers': 4, 'optimizer': 'rmsprop', 'units': 50}\n",
      "Validation accuracy: 0.9846385518709818\n",
      "Training with params: {'activation': 'relu', 'hidden_layers': 4, 'optimizer': 'rmsprop', 'units': 100}\n",
      "Validation accuracy: 0.9840176105499268\n",
      "Training with params: {'activation': 'relu', 'hidden_layers': 4, 'optimizer': 'rmsprop', 'units': 200}\n",
      "Validation accuracy: 0.9884299039840698\n",
      "Training with params: {'activation': 'relu', 'hidden_layers': 5, 'optimizer': 'adam', 'units': 50}\n",
      "Validation accuracy: 0.9856517712275187\n",
      "Training with params: {'activation': 'relu', 'hidden_layers': 5, 'optimizer': 'adam', 'units': 100}\n",
      "Validation accuracy: 0.9865014553070068\n",
      "Training with params: {'activation': 'relu', 'hidden_layers': 5, 'optimizer': 'adam', 'units': 200}\n",
      "Validation accuracy: 0.9858478109041849\n",
      "Training with params: {'activation': 'relu', 'hidden_layers': 5, 'optimizer': 'rmsprop', 'units': 50}\n",
      "Validation accuracy: 0.9864361683527628\n",
      "Training with params: {'activation': 'relu', 'hidden_layers': 5, 'optimizer': 'rmsprop', 'units': 100}\n",
      "Validation accuracy: 0.9858805537223816\n",
      "Training with params: {'activation': 'relu', 'hidden_layers': 5, 'optimizer': 'rmsprop', 'units': 200}\n",
      "Validation accuracy: 0.9874494473139445\n",
      "Training with params: {'activation': 'elu', 'hidden_layers': 3, 'optimizer': 'adam', 'units': 50}\n",
      "Validation accuracy: 0.9832658569018046\n",
      "Training with params: {'activation': 'elu', 'hidden_layers': 3, 'optimizer': 'adam', 'units': 100}\n",
      "Validation accuracy: 0.9860766132672628\n",
      "Training with params: {'activation': 'elu', 'hidden_layers': 3, 'optimizer': 'adam', 'units': 200}\n",
      "Validation accuracy: 0.9864688714345297\n",
      "Training with params: {'activation': 'elu', 'hidden_layers': 3, 'optimizer': 'rmsprop', 'units': 50}\n",
      "Validation accuracy: 0.9875147342681885\n",
      "Training with params: {'activation': 'elu', 'hidden_layers': 3, 'optimizer': 'rmsprop', 'units': 100}\n",
      "Validation accuracy: 0.9881357351938883\n",
      "Training with params: {'activation': 'elu', 'hidden_layers': 3, 'optimizer': 'rmsprop', 'units': 200}\n",
      "Validation accuracy: 0.9846057891845703\n",
      "Training with params: {'activation': 'elu', 'hidden_layers': 4, 'optimizer': 'adam', 'units': 50}\n",
      "Validation accuracy: 0.9859459201494852\n",
      "Training with params: {'activation': 'elu', 'hidden_layers': 4, 'optimizer': 'adam', 'units': 100}\n",
      "Validation accuracy: 0.984344482421875\n",
      "Training with params: {'activation': 'elu', 'hidden_layers': 4, 'optimizer': 'adam', 'units': 200}\n",
      "Validation accuracy: 0.9835925300916036\n",
      "Training with params: {'activation': 'elu', 'hidden_layers': 4, 'optimizer': 'rmsprop', 'units': 50}\n",
      "Validation accuracy: 0.985325038433075\n",
      "Training with params: {'activation': 'elu', 'hidden_layers': 4, 'optimizer': 'rmsprop', 'units': 100}\n",
      "Validation accuracy: 0.9872206052144369\n",
      "Training with params: {'activation': 'elu', 'hidden_layers': 4, 'optimizer': 'rmsprop', 'units': 200}\n",
      "Validation accuracy: 0.9838541746139526\n",
      "Training with params: {'activation': 'elu', 'hidden_layers': 5, 'optimizer': 'adam', 'units': 50}\n",
      "Validation accuracy: 0.9855209787686666\n",
      "Training with params: {'activation': 'elu', 'hidden_layers': 5, 'optimizer': 'adam', 'units': 100}\n",
      "Validation accuracy: 0.9798341194788615\n",
      "Training with params: {'activation': 'elu', 'hidden_layers': 5, 'optimizer': 'adam', 'units': 200}\n",
      "Validation accuracy: 0.9836579958597819\n",
      "Training with params: {'activation': 'elu', 'hidden_layers': 5, 'optimizer': 'rmsprop', 'units': 50}\n",
      "Validation accuracy: 0.985619068145752\n",
      "Training with params: {'activation': 'elu', 'hidden_layers': 5, 'optimizer': 'rmsprop', 'units': 100}\n",
      "Validation accuracy: 0.9882664879163107\n",
      "Training with params: {'activation': 'elu', 'hidden_layers': 5, 'optimizer': 'rmsprop', 'units': 200}\n",
      "Validation accuracy: 0.986959179242452\n",
      "Best validation accuracy: 0.9884299039840698\n",
      "Best parameters: {'activation': 'relu', 'hidden_layers': 4, 'optimizer': 'rmsprop', 'units': 200}\n",
      "Epoch 1/5\n",
      "\u001b[1m957/957\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.9429 - loss: 0.1752\n",
      "Epoch 2/5\n",
      "\u001b[1m957/957\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.9862 - loss: 0.0506\n",
      "Epoch 3/5\n",
      "\u001b[1m957/957\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.9917 - loss: 0.0267\n",
      "Epoch 4/5\n",
      "\u001b[1m957/957\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.9958 - loss: 0.0162\n",
      "Epoch 5/5\n",
      "\u001b[1m957/957\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.9957 - loss: 0.0168\n",
      "Test accuracy: 0.9920217990875244\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from sklearn.model_selection import KFold, ParameterGrid\n",
    "import numpy as np\n",
    "\n",
    "# Load the MNIST dataset\n",
    "(x_train_full, y_train_full), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "# Filter digits 0 to 4\n",
    "train_mask = (y_train_full < 5)\n",
    "test_mask = (y_test < 5)\n",
    "x_train = x_train_full[train_mask]\n",
    "y_train = y_train_full[train_mask]\n",
    "x_test = x_test[test_mask]\n",
    "y_test = y_test[test_mask]\n",
    "\n",
    "# Preprocess the data\n",
    "x_train = x_train.reshape(-1, 28*28).astype('float32') / 255.0\n",
    "x_test = x_test.reshape(-1, 28*28).astype('float32') / 255.0\n",
    "\n",
    "# Define a function to create the model\n",
    "def create_model(hidden_layers=5, units=100, activation='elu', optimizer='adam'):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(units, activation=activation, input_shape=(784,), kernel_initializer='he_normal'))\n",
    "    for _ in range(hidden_layers - 1):\n",
    "        model.add(Dense(units, activation=activation, kernel_initializer='he_normal'))\n",
    "    model.add(Dense(5, activation='softmax'))  # 5 output classes\n",
    "    model.compile(optimizer=optimizer,\n",
    "                  loss='sparse_categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Define hyperparameters and their possible values\n",
    "param_grid = {\n",
    "    'hidden_layers': [3, 4, 5],\n",
    "    'units': [50, 100, 200],\n",
    "    'activation': ['relu', 'elu'],\n",
    "    'optimizer': ['adam', 'rmsprop']\n",
    "}\n",
    "\n",
    "# Perform cross-validation\n",
    "kf = KFold(n_splits=3, shuffle=True, random_state=42)\n",
    "best_score = 0\n",
    "best_params = {}\n",
    "\n",
    "for params in ParameterGrid(param_grid):\n",
    "    print(\"Training with params:\", params)\n",
    "    scores = []\n",
    "    for train_index, val_index in kf.split(x_train):\n",
    "        X_train_cv, X_val = x_train[train_index], x_train[val_index]\n",
    "        y_train_cv, y_val = y_train[train_index], y_train[val_index]\n",
    "        \n",
    "        model = create_model(**params)\n",
    "        history = model.fit(X_train_cv, y_train_cv,\n",
    "                            epochs=5,\n",
    "                            batch_size=32,\n",
    "                            validation_data=(X_val, y_val),\n",
    "                            verbose=0)\n",
    "        \n",
    "        _, accuracy = model.evaluate(X_val, y_val, verbose=0)\n",
    "        scores.append(accuracy)\n",
    "        \n",
    "    mean_score = np.mean(scores)\n",
    "    print(\"Validation accuracy:\", mean_score)\n",
    "    \n",
    "    if mean_score > best_score:\n",
    "        best_score = mean_score\n",
    "        best_params = params\n",
    "\n",
    "print(\"Best validation accuracy:\", best_score)\n",
    "print(\"Best parameters:\", best_params)\n",
    "\n",
    "# Train the best model on the full training set\n",
    "final_model = create_model(**best_params)\n",
    "final_model.fit(x_train, y_train, epochs=5, batch_size=32, verbose=1)\n",
    "\n",
    "# Evaluate the final model on the test set\n",
    "test_loss, test_accuracy = final_model.evaluate(x_test, y_test, verbose=0)\n",
    "print(\"Test accuracy:\", test_accuracy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "JSdDybWgVkxb",
   "metadata": {
    "id": "JSdDybWgVkxb"
   },
   "source": [
    "**d. Now try adding Batch Normalization and compare the learning curves: is it\n",
    "converging faster than before? Does it produce a better model?**\n",
    "\n",
    "**Ans:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "dae94a0f-8403-47d0-90a7-d552f7fb090f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with params: {'activation': 'relu', 'hidden_layers': 3, 'optimizer': 'adam', 'units': 50, 'use_batch_norm': True}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\anacondaInstalledHere\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 0.9867630203564962\n",
      "Training with params: {'activation': 'relu', 'hidden_layers': 3, 'optimizer': 'adam', 'units': 50, 'use_batch_norm': False}\n",
      "Validation accuracy: 0.9848020871480306\n",
      "Training with params: {'activation': 'relu', 'hidden_layers': 3, 'optimizer': 'adam', 'units': 100, 'use_batch_norm': True}\n",
      "Validation accuracy: 0.9873512983322144\n",
      "Training with params: {'activation': 'relu', 'hidden_layers': 3, 'optimizer': 'adam', 'units': 100, 'use_batch_norm': False}\n",
      "Validation accuracy: 0.9869264562924703\n",
      "Training with params: {'activation': 'relu', 'hidden_layers': 3, 'optimizer': 'adam', 'units': 200, 'use_batch_norm': True}\n",
      "Validation accuracy: 0.9857497215270996\n",
      "Training with params: {'activation': 'relu', 'hidden_layers': 3, 'optimizer': 'adam', 'units': 200, 'use_batch_norm': False}\n",
      "Validation accuracy: 0.9847364028294882\n",
      "Training with params: {'activation': 'relu', 'hidden_layers': 3, 'optimizer': 'rmsprop', 'units': 50, 'use_batch_norm': True}\n",
      "Validation accuracy: 0.9876454472541809\n",
      "Training with params: {'activation': 'relu', 'hidden_layers': 3, 'optimizer': 'rmsprop', 'units': 50, 'use_batch_norm': False}\n",
      "Validation accuracy: 0.9860112468401591\n",
      "Training with params: {'activation': 'relu', 'hidden_layers': 3, 'optimizer': 'rmsprop', 'units': 100, 'use_batch_norm': True}\n",
      "Validation accuracy: 0.9892470439275106\n",
      "Training with params: {'activation': 'relu', 'hidden_layers': 3, 'optimizer': 'rmsprop', 'units': 100, 'use_batch_norm': False}\n",
      "Validation accuracy: 0.9872859716415405\n",
      "Training with params: {'activation': 'relu', 'hidden_layers': 3, 'optimizer': 'rmsprop', 'units': 200, 'use_batch_norm': True}\n",
      "Validation accuracy: 0.9888547658920288\n",
      "Training with params: {'activation': 'relu', 'hidden_layers': 3, 'optimizer': 'rmsprop', 'units': 200, 'use_batch_norm': False}\n",
      "Validation accuracy: 0.9873839219411215\n",
      "Training with params: {'activation': 'relu', 'hidden_layers': 4, 'optimizer': 'adam', 'units': 50, 'use_batch_norm': True}\n",
      "Validation accuracy: 0.984769344329834\n",
      "Training with params: {'activation': 'relu', 'hidden_layers': 4, 'optimizer': 'adam', 'units': 50, 'use_batch_norm': False}\n",
      "Validation accuracy: 0.9859458605448405\n",
      "Training with params: {'activation': 'relu', 'hidden_layers': 4, 'optimizer': 'adam', 'units': 100, 'use_batch_norm': True}\n",
      "Validation accuracy: 0.9876128236452738\n",
      "Training with params: {'activation': 'relu', 'hidden_layers': 4, 'optimizer': 'adam', 'units': 100, 'use_batch_norm': False}\n",
      "Validation accuracy: 0.9847038785616556\n",
      "Training with params: {'activation': 'relu', 'hidden_layers': 4, 'optimizer': 'adam', 'units': 200, 'use_batch_norm': True}\n",
      "Validation accuracy: 0.9874167641003927\n",
      "Training with params: {'activation': 'relu', 'hidden_layers': 4, 'optimizer': 'adam', 'units': 200, 'use_batch_norm': False}\n",
      "Validation accuracy: 0.9861746231714884\n",
      "Training with params: {'activation': 'relu', 'hidden_layers': 4, 'optimizer': 'rmsprop', 'units': 50, 'use_batch_norm': True}\n",
      "Validation accuracy: 0.9867303172747294\n",
      "Training with params: {'activation': 'relu', 'hidden_layers': 4, 'optimizer': 'rmsprop', 'units': 50, 'use_batch_norm': False}\n",
      "Validation accuracy: 0.9874167243639628\n",
      "Training with params: {'activation': 'relu', 'hidden_layers': 4, 'optimizer': 'rmsprop', 'units': 100, 'use_batch_norm': True}\n",
      "Validation accuracy: 0.9893123706181844\n",
      "Training with params: {'activation': 'relu', 'hidden_layers': 4, 'optimizer': 'rmsprop', 'units': 100, 'use_batch_norm': False}\n",
      "Validation accuracy: 0.9876127243041992\n",
      "Training with params: {'activation': 'relu', 'hidden_layers': 4, 'optimizer': 'rmsprop', 'units': 200, 'use_batch_norm': True}\n",
      "Validation accuracy: 0.9887566963831583\n",
      "Training with params: {'activation': 'relu', 'hidden_layers': 4, 'optimizer': 'rmsprop', 'units': 200, 'use_batch_norm': False}\n",
      "Validation accuracy: 0.9889201323191324\n",
      "Training with params: {'activation': 'relu', 'hidden_layers': 5, 'optimizer': 'adam', 'units': 50, 'use_batch_norm': True}\n",
      "Validation accuracy: 0.9832331935564677\n",
      "Training with params: {'activation': 'relu', 'hidden_layers': 5, 'optimizer': 'adam', 'units': 50, 'use_batch_norm': False}\n",
      "Validation accuracy: 0.9830370744069418\n",
      "Training with params: {'activation': 'relu', 'hidden_layers': 5, 'optimizer': 'adam', 'units': 100, 'use_batch_norm': True}\n",
      "Validation accuracy: 0.9863381385803223\n",
      "Training with params: {'activation': 'relu', 'hidden_layers': 5, 'optimizer': 'adam', 'units': 100, 'use_batch_norm': False}\n",
      "Validation accuracy: 0.9850308100382487\n",
      "Training with params: {'activation': 'relu', 'hidden_layers': 5, 'optimizer': 'adam', 'units': 200, 'use_batch_norm': True}\n",
      "Validation accuracy: 0.9880050222078959\n",
      "Training with params: {'activation': 'relu', 'hidden_layers': 5, 'optimizer': 'adam', 'units': 200, 'use_batch_norm': False}\n",
      "Validation accuracy: 0.9860439896583557\n",
      "Training with params: {'activation': 'relu', 'hidden_layers': 5, 'optimizer': 'rmsprop', 'units': 50, 'use_batch_norm': True}\n",
      "Validation accuracy: 0.986174742380778\n",
      "Training with params: {'activation': 'relu', 'hidden_layers': 5, 'optimizer': 'rmsprop', 'units': 50, 'use_batch_norm': False}\n",
      "Validation accuracy: 0.9797684947649637\n",
      "Training with params: {'activation': 'relu', 'hidden_layers': 5, 'optimizer': 'rmsprop', 'units': 100, 'use_batch_norm': True}\n",
      "Validation accuracy: 0.9882338047027588\n",
      "Training with params: {'activation': 'relu', 'hidden_layers': 5, 'optimizer': 'rmsprop', 'units': 100, 'use_batch_norm': False}\n",
      "Validation accuracy: 0.9871552387873331\n",
      "Training with params: {'activation': 'relu', 'hidden_layers': 5, 'optimizer': 'rmsprop', 'units': 200, 'use_batch_norm': True}\n",
      "Validation accuracy: 0.9879723191261292\n",
      "Training with params: {'activation': 'relu', 'hidden_layers': 5, 'optimizer': 'rmsprop', 'units': 200, 'use_batch_norm': False}\n",
      "Validation accuracy: 0.9868282874425253\n",
      "Training with params: {'activation': 'elu', 'hidden_layers': 3, 'optimizer': 'adam', 'units': 50, 'use_batch_norm': True}\n",
      "Validation accuracy: 0.9861747225125631\n",
      "Training with params: {'activation': 'elu', 'hidden_layers': 3, 'optimizer': 'adam', 'units': 50, 'use_batch_norm': False}\n",
      "Validation accuracy: 0.9846058090527853\n",
      "Training with params: {'activation': 'elu', 'hidden_layers': 3, 'optimizer': 'adam', 'units': 100, 'use_batch_norm': True}\n",
      "Validation accuracy: 0.9899660348892212\n",
      "Training with params: {'activation': 'elu', 'hidden_layers': 3, 'optimizer': 'adam', 'units': 100, 'use_batch_norm': False}\n",
      "Validation accuracy: 0.9862727920214335\n",
      "Training with params: {'activation': 'elu', 'hidden_layers': 3, 'optimizer': 'adam', 'units': 200, 'use_batch_norm': True}\n",
      "Validation accuracy: 0.9867630004882812\n",
      "Training with params: {'activation': 'elu', 'hidden_layers': 3, 'optimizer': 'adam', 'units': 200, 'use_batch_norm': False}\n",
      "Validation accuracy: 0.9823833902676901\n",
      "Training with params: {'activation': 'elu', 'hidden_layers': 3, 'optimizer': 'rmsprop', 'units': 50, 'use_batch_norm': True}\n",
      "Validation accuracy: 0.9875474373499552\n",
      "Training with params: {'activation': 'elu', 'hidden_layers': 3, 'optimizer': 'rmsprop', 'units': 50, 'use_batch_norm': False}\n",
      "Validation accuracy: 0.9870245059331259\n",
      "Training with params: {'activation': 'elu', 'hidden_layers': 3, 'optimizer': 'rmsprop', 'units': 100, 'use_batch_norm': True}\n",
      "Validation accuracy: 0.9899987578392029\n",
      "Training with params: {'activation': 'elu', 'hidden_layers': 3, 'optimizer': 'rmsprop', 'units': 100, 'use_batch_norm': False}\n",
      "Validation accuracy: 0.9857170780499777\n",
      "Training with params: {'activation': 'elu', 'hidden_layers': 3, 'optimizer': 'rmsprop', 'units': 200, 'use_batch_norm': True}\n",
      "Validation accuracy: 0.9899987379709879\n",
      "Training with params: {'activation': 'elu', 'hidden_layers': 3, 'optimizer': 'rmsprop', 'units': 200, 'use_batch_norm': False}\n",
      "Validation accuracy: 0.9838213523228964\n",
      "Training with params: {'activation': 'elu', 'hidden_layers': 4, 'optimizer': 'adam', 'units': 50, 'use_batch_norm': True}\n",
      "Validation accuracy: 0.9873513380686442\n",
      "Training with params: {'activation': 'elu', 'hidden_layers': 4, 'optimizer': 'adam', 'units': 50, 'use_batch_norm': False}\n",
      "Validation accuracy: 0.983854075272878\n",
      "Training with params: {'activation': 'elu', 'hidden_layers': 4, 'optimizer': 'adam', 'units': 100, 'use_batch_norm': True}\n",
      "Validation accuracy: 0.9876454671223959\n",
      "Training with params: {'activation': 'elu', 'hidden_layers': 4, 'optimizer': 'adam', 'units': 100, 'use_batch_norm': False}\n",
      "Validation accuracy: 0.9848020076751709\n",
      "Training with params: {'activation': 'elu', 'hidden_layers': 4, 'optimizer': 'adam', 'units': 200, 'use_batch_norm': True}\n",
      "Validation accuracy: 0.9883971611658732\n",
      "Training with params: {'activation': 'elu', 'hidden_layers': 4, 'optimizer': 'adam', 'units': 200, 'use_batch_norm': False}\n",
      "Validation accuracy: 0.9834292332331339\n",
      "Training with params: {'activation': 'elu', 'hidden_layers': 4, 'optimizer': 'rmsprop', 'units': 50, 'use_batch_norm': True}\n",
      "Validation accuracy: 0.9884953101476034\n",
      "Training with params: {'activation': 'elu', 'hidden_layers': 4, 'optimizer': 'rmsprop', 'units': 50, 'use_batch_norm': False}\n",
      "Validation accuracy: 0.9843770662943522\n",
      "Training with params: {'activation': 'elu', 'hidden_layers': 4, 'optimizer': 'rmsprop', 'units': 100, 'use_batch_norm': True}\n",
      "Validation accuracy: 0.9876454671223959\n",
      "Training with params: {'activation': 'elu', 'hidden_layers': 4, 'optimizer': 'rmsprop', 'units': 100, 'use_batch_norm': False}\n",
      "Validation accuracy: 0.986566960811615\n",
      "Training with params: {'activation': 'elu', 'hidden_layers': 4, 'optimizer': 'rmsprop', 'units': 200, 'use_batch_norm': True}\n",
      "Validation accuracy: 0.987678070863088\n",
      "Training with params: {'activation': 'elu', 'hidden_layers': 4, 'optimizer': 'rmsprop', 'units': 200, 'use_batch_norm': False}\n",
      "Validation accuracy: 0.9859785834948221\n",
      "Training with params: {'activation': 'elu', 'hidden_layers': 5, 'optimizer': 'adam', 'units': 50, 'use_batch_norm': True}\n",
      "Validation accuracy: 0.9863707224527994\n",
      "Training with params: {'activation': 'elu', 'hidden_layers': 5, 'optimizer': 'adam', 'units': 50, 'use_batch_norm': False}\n",
      "Validation accuracy: 0.982546846071879\n",
      "Training with params: {'activation': 'elu', 'hidden_layers': 5, 'optimizer': 'adam', 'units': 100, 'use_batch_norm': True}\n",
      "Validation accuracy: 0.9856517116228739\n",
      "Training with params: {'activation': 'elu', 'hidden_layers': 5, 'optimizer': 'adam', 'units': 100, 'use_batch_norm': False}\n",
      "Validation accuracy: 0.9822853406270345\n",
      "Training with params: {'activation': 'elu', 'hidden_layers': 5, 'optimizer': 'adam', 'units': 200, 'use_batch_norm': True}\n",
      "Validation accuracy: 0.9870898524920145\n",
      "Training with params: {'activation': 'elu', 'hidden_layers': 5, 'optimizer': 'adam', 'units': 200, 'use_batch_norm': False}\n",
      "Validation accuracy: 0.9813047051429749\n",
      "Training with params: {'activation': 'elu', 'hidden_layers': 5, 'optimizer': 'rmsprop', 'units': 50, 'use_batch_norm': True}\n",
      "Validation accuracy: 0.9865669210751852\n",
      "Training with params: {'activation': 'elu', 'hidden_layers': 5, 'optimizer': 'rmsprop', 'units': 50, 'use_batch_norm': False}\n",
      "Validation accuracy: 0.9831023414929708\n",
      "Training with params: {'activation': 'elu', 'hidden_layers': 5, 'optimizer': 'rmsprop', 'units': 100, 'use_batch_norm': True}\n",
      "Validation accuracy: 0.9876128236452738\n",
      "Training with params: {'activation': 'elu', 'hidden_layers': 5, 'optimizer': 'rmsprop', 'units': 100, 'use_batch_norm': False}\n",
      "Validation accuracy: 0.9849326610565186\n",
      "Training with params: {'activation': 'elu', 'hidden_layers': 5, 'optimizer': 'rmsprop', 'units': 200, 'use_batch_norm': True}\n",
      "Validation accuracy: 0.987678070863088\n",
      "Training with params: {'activation': 'elu', 'hidden_layers': 5, 'optimizer': 'rmsprop', 'units': 200, 'use_batch_norm': False}\n",
      "Validation accuracy: 0.9832003513971964\n",
      "Best validation accuracy: 0.9899987578392029\n",
      "Best parameters: {'activation': 'elu', 'hidden_layers': 3, 'optimizer': 'rmsprop', 'units': 100, 'use_batch_norm': True}\n",
      "Epoch 1/5\n",
      "\u001b[1m765/765\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.9339 - loss: 0.2014 - val_accuracy: 0.9882 - val_loss: 0.0421\n",
      "Epoch 2/5\n",
      "\u001b[1m765/765\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9836 - loss: 0.0575 - val_accuracy: 0.9889 - val_loss: 0.0360\n",
      "Epoch 3/5\n",
      "\u001b[1m765/765\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9877 - loss: 0.0377 - val_accuracy: 0.9897 - val_loss: 0.0369\n",
      "Epoch 4/5\n",
      "\u001b[1m765/765\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9889 - loss: 0.0342 - val_accuracy: 0.9905 - val_loss: 0.0294\n",
      "Epoch 5/5\n",
      "\u001b[1m765/765\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9929 - loss: 0.0206 - val_accuracy: 0.9912 - val_loss: 0.0333\n",
      "Test accuracy: 0.9908542633056641\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, BatchNormalization\n",
    "from sklearn.model_selection import KFold, ParameterGrid\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the MNIST dataset\n",
    "(x_train_full, y_train_full), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "# Filter digits 0 to 4\n",
    "train_mask = (y_train_full < 5)\n",
    "test_mask = (y_test < 5)\n",
    "x_train = x_train_full[train_mask]\n",
    "y_train = y_train_full[train_mask]\n",
    "x_test = x_test[test_mask]\n",
    "y_test = y_test[test_mask]\n",
    "\n",
    "# Preprocess the data\n",
    "x_train = x_train.reshape(-1, 28*28).astype('float32') / 255.0\n",
    "x_test = x_test.reshape(-1, 28*28).astype('float32') / 255.0\n",
    "\n",
    "# Define a function to create the model\n",
    "def create_model(hidden_layers=5, units=100, activation='elu', optimizer='adam', use_batch_norm=True):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(units, activation=activation, input_shape=(784,), kernel_initializer='he_normal'))\n",
    "    if use_batch_norm:\n",
    "        model.add(BatchNormalization())\n",
    "    for _ in range(hidden_layers - 1):\n",
    "        model.add(Dense(units, activation=activation, kernel_initializer='he_normal'))\n",
    "        if use_batch_norm:\n",
    "            model.add(BatchNormalization())\n",
    "    model.add(Dense(5, activation='softmax'))  # 5 output classes\n",
    "    model.compile(optimizer=optimizer,\n",
    "                  loss='sparse_categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Define hyperparameters and their possible values\n",
    "param_grid = {\n",
    "    'hidden_layers': [3, 4, 5],\n",
    "    'units': [50, 100, 200],\n",
    "    'activation': ['relu', 'elu'],\n",
    "    'optimizer': ['adam', 'rmsprop'],\n",
    "    'use_batch_norm': [True, False]\n",
    "}\n",
    "\n",
    "# Perform cross-validation\n",
    "kf = KFold(n_splits=3, shuffle=True, random_state=42)\n",
    "best_score = 0\n",
    "best_params = {}\n",
    "\n",
    "for params in ParameterGrid(param_grid):\n",
    "    print(\"Training with params:\", params)\n",
    "    scores = []\n",
    "    for train_index, val_index in kf.split(x_train):\n",
    "        X_train_cv, X_val = x_train[train_index], x_train[val_index]\n",
    "        y_train_cv, y_val = y_train[train_index], y_train[val_index]\n",
    "        \n",
    "        model = create_model(**params)\n",
    "        history = model.fit(X_train_cv, y_train_cv,\n",
    "                            epochs=5,\n",
    "                            batch_size=32,\n",
    "                            validation_data=(X_val, y_val),\n",
    "                            verbose=0)\n",
    "        \n",
    "        _, accuracy = model.evaluate(X_val, y_val, verbose=0)\n",
    "        scores.append(accuracy)\n",
    "        \n",
    "    mean_score = np.mean(scores)\n",
    "    print(\"Validation accuracy:\", mean_score)\n",
    "    \n",
    "    if mean_score > best_score:\n",
    "        best_score = mean_score\n",
    "        best_params = params\n",
    "\n",
    "print(\"Best validation accuracy:\", best_score)\n",
    "print(\"Best parameters:\", best_params)\n",
    "\n",
    "# Train the best model on the full training set\n",
    "final_model = create_model(**best_params)\n",
    "history = final_model.fit(x_train, y_train, epochs=5, batch_size=32, verbose=1, validation_split=0.2)\n",
    "\n",
    "# Evaluate the final model on the test set\n",
    "test_loss, test_accuracy = final_model.evaluate(x_test, y_test, verbose=0)\n",
    "print(\"Test accuracy:\", test_accuracy)\n",
    "\n",
    "# Plot the learning curves\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lV80nqE5dvgp",
   "metadata": {
    "id": "lV80nqE5dvgp"
   },
   "source": [
    "**e. Is the model overfitting the training set? Try adding dropout to every layer and try again. Does it help?**\n",
    "\n",
    "**Ans:** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "4e7dfc03-a444-41a3-a88e-168cfd170cca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the MNIST dataset\n",
    "(x_train_full, y_train_full), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "# Filter digits 0 to 4\n",
    "train_mask = (y_train_full < 5)\n",
    "test_mask = (y_test < 5)\n",
    "x_train = x_train_full[train_mask]\n",
    "y_train = y_train_full[train_mask]\n",
    "x_test = x_test[test_mask]\n",
    "y_test = y_test[test_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "oHGKyucNd4f9",
   "metadata": {
    "id": "oHGKyucNd4f9"
   },
   "outputs": [],
   "source": [
    "# Build DNN with Dropout\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    keras.layers.Dropout(rate=0.2),\n",
    "    keras.layers.Dense(100, activation=\"elu\", kernel_initializer=\"he_normal\"),\n",
    "    keras.layers.Dropout(rate=0.2),\n",
    "    keras.layers.Dense(100, activation=\"elu\", kernel_initializer=\"he_normal\"),\n",
    "    keras.layers.Dropout(rate=0.2),\n",
    "    keras.layers.Dense(100, activation=\"elu\", kernel_initializer=\"he_normal\"),\n",
    "    keras.layers.Dropout(rate=0.2),\n",
    "    keras.layers.Dense(100, activation=\"elu\", kernel_initializer=\"he_normal\"),\n",
    "    keras.layers.Dropout(rate=0.2),\n",
    "    keras.layers.Dense(5, activation=\"softmax\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "X9e4D9VrecIA",
   "metadata": {
    "id": "X9e4D9VrecIA"
   },
   "outputs": [],
   "source": [
    "# Compile model\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "              optimizer=keras.optimizers.Adam(),\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "SRqt461nefgx",
   "metadata": {
    "id": "SRqt461nefgx"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m957/957\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.8423 - loss: 0.9594\n",
      "Epoch 2/10\n",
      "\u001b[1m 22/957\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.8789 - loss: 0.4172"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\anacondaInstalledHere\\Lib\\site-packages\\keras\\src\\callbacks\\early_stopping.py:155: UserWarning: Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: accuracy,loss\n",
      "  current = self.get_monitor_value(logs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m957/957\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.8822 - loss: 0.4592\n",
      "Epoch 3/10\n",
      "\u001b[1m957/957\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.9169 - loss: 0.3173\n",
      "Epoch 4/10\n",
      "\u001b[1m957/957\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.9306 - loss: 0.2538\n",
      "Epoch 5/10\n",
      "\u001b[1m957/957\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.9481 - loss: 0.1942\n",
      "Epoch 6/10\n",
      "\u001b[1m957/957\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.9540 - loss: 0.1683\n",
      "Epoch 7/10\n",
      "\u001b[1m957/957\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.9572 - loss: 0.1621\n",
      "Epoch 8/10\n",
      "\u001b[1m957/957\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.9619 - loss: 0.1370\n",
      "Epoch 9/10\n",
      "\u001b[1m957/957\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - accuracy: 0.9657 - loss: 0.1366\n",
      "Epoch 10/10\n",
      "\u001b[1m957/957\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9687 - loss: 0.1176\n"
     ]
    }
   ],
   "source": [
    "# Train model\n",
    "history_dropout = model.fit(x_train, y_train, epochs=10, batch_size=32,\n",
    "                            callbacks=[early_stopping_cb])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28cdf155-1916-4688-be4a-5f6e726052a0",
   "metadata": {},
   "source": [
    "**2. Transfer learning.**\n",
    "\n",
    "**a. Create a new DNN that reuses all the pretrained hidden layers of the previous model, freezes them, and replaces the softmax output layer with a new one.**\n",
    "\n",
    "**b. Train this new DNN on digits 5 to 9, using only 100 images per digit, and time how long it takes. Despite this small number of examples, can you achieve high precision?**\n",
    "\n",
    "**c. Try caching the frozen layers, and train the model again: how much faster is it now?**\n",
    "\n",
    "**d. Try again reusing just four hidden layers instead of five. Can you achieve a higher precision?**\n",
    "\n",
    "**e. Now unfreeze the top two hidden layers and continue training: can you get the model to perform even better?**\n",
    "\n",
    "**Ans:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "27018961-e009-4b2c-8eeb-ec91fa3b878b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a067180b-7ac9-406a-bde9-3e4b43dee284",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_4\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_4\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ dense_21 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)                 │          <span style=\"color: #00af00; text-decoration-color: #00af00\">78,500</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_22 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)                 │          <span style=\"color: #00af00; text-decoration-color: #00af00\">10,100</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_23 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)                 │          <span style=\"color: #00af00; text-decoration-color: #00af00\">10,100</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_24 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)                 │          <span style=\"color: #00af00; text-decoration-color: #00af00\">10,100</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_25 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)                 │          <span style=\"color: #00af00; text-decoration-color: #00af00\">10,100</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_26 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)                   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">505</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ dense_21 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)                 │          \u001b[38;5;34m78,500\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_22 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)                 │          \u001b[38;5;34m10,100\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_23 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)                 │          \u001b[38;5;34m10,100\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_24 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)                 │          \u001b[38;5;34m10,100\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_25 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)                 │          \u001b[38;5;34m10,100\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_26 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m)                   │             \u001b[38;5;34m505\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">119,407</span> (466.44 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m119,407\u001b[0m (466.44 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">119,405</span> (466.43 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m119,405\u001b[0m (466.43 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2</span> (12.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m2\u001b[0m (12.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load the pretrained model\n",
    "pretrained_model = keras.models.load_model(\"mnist_model_0_to_4.h5\")\n",
    "pretrained_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "93cf579e-a74d-40ad-bb8f-efcdf74a37e7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create a new DNN that reuses all the pretrained hidden layers of the previous model\n",
    "new_model = keras.models.Sequential(pretrained_model.layers[:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "09219fa1-ea89-4398-b9d8-8fc6be4bdf56",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Freeze the reused layers\n",
    "for layer in new_model.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e28deb34-28f4-4fc7-a705-5eb8bbd3a87f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Add a new softmax output layer with the desired number of units\n",
    "new_model.add(keras.layers.Dense(5, activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7fef98e5-995f-47b8-a05d-13f5b652281c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Compile the new model\n",
    "new_model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"sgd\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d4446eba-c860-47d7-8b79-7e354d805820",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load the training data for digits 5 to 9\n",
    "(X_train, y_train), (X_test, y_test) = keras.datasets.mnist.load_data()\n",
    "X_train = X_train[y_train >= 5]\n",
    "y_train = y_train[y_train >= 5] - 5\n",
    "X_test = X_test[y_test >= 5]\n",
    "y_test = y_test[y_test >= 5] - 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "565a43b4-e3f3-4542-b1df-e0ed3c49ba43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess the data\n",
    "X_train = X_train.reshape(-1, 28*28).astype('float32') / 255.0\n",
    "X_test = X_test.reshape(-1, 28*28).astype('float32') / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4db07155-72f0-4329-99df-a65590e837d1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 97ms/step - accuracy: 0.3235 - loss: 2.5496 - val_accuracy: 0.5616 - val_loss: 1.3963\n",
      "Epoch 2/10\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - accuracy: 0.6361 - loss: 1.1244 - val_accuracy: 0.6100 - val_loss: 1.1161\n",
      "Epoch 3/10\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - accuracy: 0.7065 - loss: 0.8864 - val_accuracy: 0.6515 - val_loss: 0.9743\n",
      "Epoch 4/10\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 42ms/step - accuracy: 0.7021 - loss: 0.8081 - val_accuracy: 0.6739 - val_loss: 0.9197\n",
      "Epoch 5/10\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - accuracy: 0.7539 - loss: 0.6878 - val_accuracy: 0.6776 - val_loss: 0.8947\n",
      "Epoch 6/10\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - accuracy: 0.7522 - loss: 0.6948 - val_accuracy: 0.6896 - val_loss: 0.8618\n",
      "Epoch 7/10\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - accuracy: 0.7707 - loss: 0.6596 - val_accuracy: 0.7073 - val_loss: 0.8238\n",
      "Epoch 8/10\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 51ms/step - accuracy: 0.7820 - loss: 0.6451 - val_accuracy: 0.7054 - val_loss: 0.8185\n",
      "Epoch 9/10\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 50ms/step - accuracy: 0.7697 - loss: 0.6552 - val_accuracy: 0.7188 - val_loss: 0.7935\n",
      "Epoch 10/10\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - accuracy: 0.8175 - loss: 0.5678 - val_accuracy: 0.7254 - val_loss: 0.7844\n"
     ]
    }
   ],
   "source": [
    "# Train the new model on digits 5 to 9 using only 100 images per digit\n",
    "history = new_model.fit(X_train[:500], y_train[:500], epochs=10, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "012eee0b-cba7-4dc5-8190-972b928f7b1d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6996 - loss: 0.8503\n",
      "Test accuracy: 0.725365161895752\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the trained model\n",
    "test_loss, test_acc = new_model.evaluate(X_test, y_test)\n",
    "print(f\"Test accuracy: {test_acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e8d32853-d109-4513-a83f-9f80ba08082d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 87ms/step - accuracy: 0.7979 - loss: 0.5965 - val_accuracy: 0.7461 - val_loss: 0.7336\n",
      "Epoch 2/10\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - accuracy: 0.8617 - loss: 0.4614 - val_accuracy: 0.7521 - val_loss: 0.7091\n",
      "Epoch 3/10\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - accuracy: 0.8489 - loss: 0.4907 - val_accuracy: 0.7638 - val_loss: 0.6945\n",
      "Epoch 4/10\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 51ms/step - accuracy: 0.8509 - loss: 0.4207 - val_accuracy: 0.7801 - val_loss: 0.6619\n",
      "Epoch 5/10\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - accuracy: 0.8480 - loss: 0.4302 - val_accuracy: 0.7842 - val_loss: 0.6506\n",
      "Epoch 6/10\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 55ms/step - accuracy: 0.8522 - loss: 0.4366 - val_accuracy: 0.7922 - val_loss: 0.6301\n",
      "Epoch 7/10\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 45ms/step - accuracy: 0.8438 - loss: 0.4336 - val_accuracy: 0.7963 - val_loss: 0.6149\n",
      "Epoch 8/10\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 52ms/step - accuracy: 0.9057 - loss: 0.3060 - val_accuracy: 0.8033 - val_loss: 0.6009\n",
      "Epoch 9/10\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 51ms/step - accuracy: 0.9041 - loss: 0.3182 - val_accuracy: 0.8093 - val_loss: 0.5847\n",
      "Epoch 10/10\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step - accuracy: 0.8999 - loss: 0.3115 - val_accuracy: 0.8126 - val_loss: 0.5737\n"
     ]
    }
   ],
   "source": [
    "# Try caching the frozen layers and train the model again\n",
    "new_model.layers[0].trainable = True\n",
    "new_model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"sgd\", metrics=[\"accuracy\"])\n",
    "history = new_model.fit(X_train[:500], y_train[:500], epochs=10, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a0175a9c-1c40-41be-b387-1df575278dd3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7915 - loss: 0.6378\n",
      "Test accuracy: 0.8125900030136108\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the trained model again\n",
    "test_loss, test_acc = new_model.evaluate(X_test, y_test)\n",
    "print(f\"Test accuracy: {test_acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "bbb2f251-1091-437a-b82d-a41636f6824e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - accuracy: 0.2836 - loss: 2.9407 - val_accuracy: 0.4915 - val_loss: 1.8192\n",
      "Epoch 2/10\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 52ms/step - accuracy: 0.6126 - loss: 1.2647 - val_accuracy: 0.6015 - val_loss: 1.3881\n",
      "Epoch 3/10\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 52ms/step - accuracy: 0.7517 - loss: 0.8705 - val_accuracy: 0.6478 - val_loss: 1.1668\n",
      "Epoch 4/10\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 52ms/step - accuracy: 0.7616 - loss: 0.8124 - val_accuracy: 0.6752 - val_loss: 1.0540\n",
      "Epoch 5/10\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 42ms/step - accuracy: 0.7712 - loss: 0.7716 - val_accuracy: 0.7029 - val_loss: 0.9562\n",
      "Epoch 6/10\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - accuracy: 0.7758 - loss: 0.6934 - val_accuracy: 0.7167 - val_loss: 0.8979\n",
      "Epoch 7/10\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.7966 - loss: 0.5815 - val_accuracy: 0.7336 - val_loss: 0.8335\n",
      "Epoch 8/10\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - accuracy: 0.7791 - loss: 0.6371 - val_accuracy: 0.7426 - val_loss: 0.7994\n",
      "Epoch 9/10\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - accuracy: 0.8027 - loss: 0.5977 - val_accuracy: 0.7599 - val_loss: 0.7564\n",
      "Epoch 10/10\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - accuracy: 0.8371 - loss: 0.4770 - val_accuracy: 0.7694 - val_loss: 0.7298\n"
     ]
    }
   ],
   "source": [
    "# Try again reusing just four hidden layers instead of five\n",
    "new_model2 = keras.models.Sequential(pretrained_model.layers[:-2])\n",
    "for layer in new_model2.layers:\n",
    "    layer.trainable = False\n",
    "new_model2.add(keras.layers.Dense(5, activation=\"softmax\"))\n",
    "new_model2.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"sgd\", metrics=[\"accuracy\"])\n",
    "history = new_model2.fit(X_train[:500], y_train[:500], epochs=10, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "933f3511-76e2-4d3e-9946-23f1359a159c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_2\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_2\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ dense_21 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)                 │          <span style=\"color: #00af00; text-decoration-color: #00af00\">78,500</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_22 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)                 │          <span style=\"color: #00af00; text-decoration-color: #00af00\">10,100</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_23 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)                 │          <span style=\"color: #00af00; text-decoration-color: #00af00\">10,100</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_24 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)                 │          <span style=\"color: #00af00; text-decoration-color: #00af00\">10,100</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)                   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">505</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ dense_21 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)                 │          \u001b[38;5;34m78,500\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_22 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)                 │          \u001b[38;5;34m10,100\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_23 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)                 │          \u001b[38;5;34m10,100\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_24 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)                 │          \u001b[38;5;34m10,100\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m)                   │             \u001b[38;5;34m505\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">109,307</span> (426.98 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m109,307\u001b[0m (426.98 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">505</span> (1.97 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m505\u001b[0m (1.97 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">108,800</span> (425.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m108,800\u001b[0m (425.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2</span> (12.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m2\u001b[0m (12.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "new_model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "280f42c2-0a48-4694-a5e7-c1e016604264",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7421 - loss: 0.8107\n",
      "Test accuracy: 0.7693890333175659\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the trained model again\n",
    "test_loss, test_acc = new_model2.evaluate(X_test, y_test)\n",
    "print(f\"Test accuracy: {test_acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "50cd9c48-71fa-4dad-ba0d-699665ea87a2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 59ms/step - accuracy: 0.8594 - loss: 0.4143 - val_accuracy: 0.7895 - val_loss: 0.6618\n",
      "Epoch 2/10\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step - accuracy: 0.8615 - loss: 0.4233 - val_accuracy: 0.7967 - val_loss: 0.6367\n",
      "Epoch 3/10\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 44ms/step - accuracy: 0.8643 - loss: 0.4111 - val_accuracy: 0.8035 - val_loss: 0.6028\n",
      "Epoch 4/10\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 63ms/step - accuracy: 0.8641 - loss: 0.3792 - val_accuracy: 0.8083 - val_loss: 0.5868\n",
      "Epoch 5/10\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 53ms/step - accuracy: 0.9082 - loss: 0.3141 - val_accuracy: 0.8190 - val_loss: 0.5487\n",
      "Epoch 6/10\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - accuracy: 0.9079 - loss: 0.2732 - val_accuracy: 0.8231 - val_loss: 0.5391\n",
      "Epoch 7/10\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 50ms/step - accuracy: 0.8917 - loss: 0.3030 - val_accuracy: 0.8356 - val_loss: 0.5103\n",
      "Epoch 8/10\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 55ms/step - accuracy: 0.9353 - loss: 0.2132 - val_accuracy: 0.8400 - val_loss: 0.5009\n",
      "Epoch 9/10\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.9230 - loss: 0.2289 - val_accuracy: 0.8422 - val_loss: 0.4927\n",
      "Epoch 10/10\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - accuracy: 0.9255 - loss: 0.2095 - val_accuracy: 0.8441 - val_loss: 0.4848\n"
     ]
    }
   ],
   "source": [
    "# Now unfreeze the top two hidden layers and continue training\n",
    "for layer in new_model2.layers[-3:]:\n",
    "    layer.trainable = True\n",
    "new_model2.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"sgd\", metrics=[\"accuracy\"])\n",
    "history = new_model2.fit(X_train[:500], y_train[:500], epochs=10, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "db44f4be-d7b7-4d8a-9894-e1031d1130fd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8238 - loss: 0.5443\n",
      "Test accuracy: 0.8440650105476379\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the trained model again\n",
    "test_loss, test_acc = new_model2.evaluate(X_test, y_test)\n",
    "print(f\"Test accuracy: {test_acc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d63bc8f-2ebe-4aec-b990-3a3540bd4320",
   "metadata": {},
   "source": [
    "**3. Pretraining on an auxiliary task.**\n",
    "\n",
    "**a. In this exercise you will build a DNN that compares two MNIST digit images and predicts whether they represent the same digit or not. Then you will reuse the lower layers of this network to train an MNIST classifier using very little training data. Start by building two DNNs (let’s call them DNN A and B), both similar to the one you built earlier but without the output layer: each DNN should have five hidden layers of 100 neurons each, He initialization, and ELU activation. Next, add one more hidden layer with 10 units on top of both DNNs. To do this, you should use TensorFlow’s concat() function with axis=1 to concatenate the outputs of both DNNs for each instance, then feed the result to the hidden layer. Finally, add an output layer with a single neuron using the logistic activation function.**\n",
    "\n",
    "**b. Split the MNIST training set in two sets: split #1 should containing 55,000 images, and split #2 should contain contain 5,000 images. Create a function that generates a training batch where each instance is a pair of MNIST images picked from split #1. Half of the training instances should be pairs of images that belong to the same class, while the other half should be images from different classes. For each pair, the training label should be 0 if the images are from the same class, or 1 if they are from different classes.**\n",
    "\n",
    "**c. Train the DNN on this training set. For each image pair, you can simultaneously feed the first image to DNN A and the second image to DNN B. The whole network will gradually learn to tell whether two images belong to the same class or not.**\n",
    "\n",
    "**d. Now create a new DNN by reusing and freezing the hidden layers of DNN A and adding a softmax output layer on top with 10 neurons. Train this network on split #2 and see if you can achieve high performance despite having only 500 images per class.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "7ef1524b-cbe4-49b8-958f-e9e378bf8fa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "e4968197-ff63-4cc5-be58-cb5f990dc413",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the MNIST dataset and split it into two sets\n",
    "(X_train_full, y_train_full), (X_test, y_test) = keras.datasets.mnist.load_data()\n",
    "X_train_full = X_train_full.astype(np.float32) / 255\n",
    "X_test = X_test.astype(np.float32) / 255\n",
    "X_train1 = X_train_full[:55000]\n",
    "y_train1 = y_train_full[:55000]\n",
    "X_train2 = X_train_full[55000:]\n",
    "y_train2 = y_train_full[55000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "5243eedd-40cc-40e6-a815-4c0a5c8924f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to generate a training batch where each instance is a pair of MNIST images\n",
    "def generate_batch(batch_size):\n",
    "    X_batch1 = np.empty((batch_size, 28, 28), dtype=np.float32)\n",
    "    X_batch2 = np.empty((batch_size, 28, 28), dtype=np.float32)\n",
    "    y_batch = np.empty((batch_size, 1), dtype=np.int32)\n",
    "    for i in range(batch_size):\n",
    "        index1 = np.random.randint(len(X_train1))\n",
    "        X_batch1[i] = X_train1[index1]\n",
    "        if i % 2 == 0:\n",
    "            # Images from the same class\n",
    "            index2 = index1\n",
    "            while index2 == index1:\n",
    "                index2 = np.random.randint(len(X_train1))\n",
    "                if y_train1[index2] == y_train1[index1]:\n",
    "                    break\n",
    "            y_batch[i] = 0\n",
    "        else:\n",
    "            # Images from different classes\n",
    "            index2 = index1\n",
    "            while index2 == index1 or y_train1[index2] == y_train1[index1]:\n",
    "                index2 = np.random.randint(len(X_train1))\n",
    "            y_batch[i] = 1\n",
    "        X_batch2[i] = X_train1[index2]\n",
    "    return [X_batch1, X_batch2], y_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "070b9bf0-b03b-4c15-a593-b532ad4f5840",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build two DNNs (let’s call them DNN A and B), both similar to the one you built earlier but without the output layer\n",
    "def build_dnn():\n",
    "    model = keras.models.Sequential()\n",
    "    model.add(keras.layers.Flatten(input_shape=[28, 28]))\n",
    "    for _ in range(5):\n",
    "        model.add(keras.layers.Dense(100, activation=\"elu\", kernel_initializer=\"he_normal\"))\n",
    "    return model\n",
    "\n",
    "dnn_a = build_dnn()\n",
    "dnn_b = build_dnn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "50ae7b67-cc8e-4da7-aaae-49c055d6c6b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the Functional API to merge their outputs\n",
    "input_a = Input(shape=(28, 28))\n",
    "input_b = Input(shape=(28, 28))\n",
    "\n",
    "# Call the Sequential models on the inputs\n",
    "output_a = dnn_a(input_a)\n",
    "output_b = dnn_b(input_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "810485ee-7a1a-499c-82a9-ec5e3bcf2f3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add one more hidden layer with 10 units on top of both DNNs\n",
    "merged_output = keras.layers.concatenate([dnn_a.output, dnn_b.output])\n",
    "hidden_layer = keras.layers.Dense(10, activation=\"elu\", kernel_initializer=\"he_normal\")(merged_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "63fbe86a-81da-460b-9ef2-66604a30922c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add an output layer with a single neuron using the logistic activation function\n",
    "output_layer = keras.layers.Dense(1, activation=\"sigmoid\")(hidden_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "77f9cbbe-68fe-414b-a488-909609f93163",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new model that takes two MNIST images as inputs and outputs a single value representing whether the images belong to the same class or not\n",
    "model = keras.models.Model(inputs=[dnn_a.input, dnn_b.input], outputs=[output_layer])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "0a1a1071-6fb6-41ea-94f7-2f2187ba35bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=\"nadam\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03c637ca-1317-4db2-accf-6ff0c7d0ab49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 9004 calls to <function TensorFlowTrainer.make_train_function.<locals>.one_step_on_iterator at 0x000001F600C45F80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 9004 calls to <function TensorFlowTrainer.make_train_function.<locals>.one_step_on_iterator at 0x000001F600C45F80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 9005 calls to <function TensorFlowTrainer.make_train_function.<locals>.one_step_on_iterator at 0x000001F600C45F80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 9005 calls to <function TensorFlowTrainer.make_train_function.<locals>.one_step_on_iterator at 0x000001F600C45F80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    }
   ],
   "source": [
    "# Train the DNN on this training set\n",
    "batch_size = 32\n",
    "for epoch in range(10):\n",
    "    for iteration in range(len(X_train1) // batch_size):\n",
    "        X_batch, y_batch = generate_batch(batch_size)\n",
    "        model.train_on_batch(X_batch, y_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff914b3a-75f5-4773-b123-dd972691bd30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new DNN by reusing and freezing the hidden layers of DNN A and adding a softmax output layer on top with 10 neurons\n",
    "new_model = keras.models.Sequential(dnn_a.layers[:-1])\n",
    "for layer in new_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "new_model.add(keras.layers.Dense(10, activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f442691a-0986-4ea5-a299-4e8f630fe6e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the new model\n",
    "new_model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"nadam\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a276d17-b751-48cd-b517-47dae4e0a682",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train this network on split #2 and see if you can achieve high performance despite having only 500 images per class\n",
    "history = new_model.fit(X_train2, y_train2, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba56b82c-88a5-4da7-87f0-5d0eec19c856",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the trained model on the test set\n",
    "test_loss, test_acc = new_model.evaluate(X_test, y_test)\n",
    "print(f\"Test accuracy: {test_acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d56df42c-43ac-4809-ac1e-6ba484aad145",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
